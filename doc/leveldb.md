# leveldb

### 关系型数据库：
　　关系型数据库，是指采用了关系模型来组织数据的数据库，最大特点就是事务的一致性。简单来说，关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织。
#### 优点
  * 容易理解：二维表结构是非常贴近逻辑世界一个概念，关系模型相对网状、层次等其他模型来说更容易理解；
  * 使用方便：通用的SQL语言使得操作关系型数据库非常方便；
  * 易于维护：丰富的完整性(实体完整性、参照完整性和用户定义的完整性)大大减低了数据冗余和数据不一致的概率；
#### 瓶颈
  * 高并发读写需求：网站的用户并发性非常高，往往达到每秒上万次读写请求，对于传统关系型数据库来说，硬盘I/O是一个很大的瓶颈
  * 海量数据的高效率读写：网站每天产生的数据量是巨大的，对于关系型数据库来说，在一张包含海量数据的表中查询，效率是非常低的
  * 高扩展性和可用性：在基于web的结构当中，数据库是最难进行横向扩展的，当一个应用系统的用户量和访问量与日俱增的时候，数据库却没有办法像web server和app server那样简单的通过添加更多的硬件和服务节点来扩展性能和负载能力。对于很多需要提供24小时不间断服务的网站来说，对数据库系统进行升级和扩展 是非常痛苦的事情，往往需要停机维护和数据迁移。
  
### 对网站来说，关系型数据库的很多特性不再需要
  * 事务一致性：关系型数据库在对事物一致性的维护中有很大的开销，而现在很多web2.0系统对事物的读写一致性都不高。
  * 读写实时性：对关系数据库来说，插入一条数据之后立刻查询，是肯定可以读出这条数据的，但是对于很多web应用来说，并不要求这么高的实时性，比如发一条消息之后，过几秒乃至十几秒之后才看到这条动态是完全可以接受的。
  * 复杂SQL，特别是多表关联查询：任何大数据量的web系统，都非常忌讳多个大表的关联查询，以及复杂的数据分析类型的复杂SQL报表查询，特别是SNS类型的网站，从需求以及产品阶级角度，就避免了这种情况的产生。往往更多的只是单表的主键查询，以及单表的简单条件分页查询，SQL的功能极大的弱化了。
  * 在关系型数据库中，导致性能欠佳的最主要原因是多表的关联查询，以及复杂的数据分析类型的复杂SQL报表查询。为了保证数据库的ACID特性，我们必须尽量按照其要求的范式进行设计，关系型数据库中的表都是存储一个格式化的数据结构。每个元组字段的组成都是一样，即使不是每个元组都需要所有的字段， 但数据库会为每个元组分配所有的字段，这样的结构可以便于标语表之间进行链接等操作，但从另一个角度来说它也是关系型数据库性能瓶颈的一个因素。
  
### 非关系型数据库出现的原因
  * 关系型数据库的最大特点就是事务的一致性：传统的关系型数据库读写操作都是事务的，具有ACID的特点，这个特性使得关系型数据库可以用于几乎所有对一致性有要求的系统中，如典型的银行系统。但是，在网页应用中，尤其是SNS应用中，一致性却不是显得那么重要，比如，两个人看到同一好友的数据更新的时间差那么几秒是可以容忍的，因此，关系型数据库的最大特点在这里已经无用武之地，起码不是那么重要了。
  * 相反地，关系型数据库为了维护一致性所付出的巨大代价就是其读写性能比较差，而像微博、facebook这类SNS的应用，对并发读写能力要求极高，关系型数据库已经无法应付（在读方面，传统上为了克服关系型数据库缺陷，提高性能，都是增加一级memcache来静态化网页，而在SNS中，变化太快，memchache已经无能为力了），因此，必须用新的一种数据结构存储来代替关系数据库。
  * 关系数据库的另一个特点就是其具有固定的表结构，因此，其扩展性极差，而在SNS中，系统的升级，功能的增加，往往意味着数据结构巨大变动，这一点关系型数据库也难以应付，需要新的结构化数据存储。
  * 于是，非关系型数据库应运而生，由于不可能用一种数据结构化存储应付所有的新的需求，因此，非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合。必须强调的是，数据的持久存储，尤其是海量数据的持久存储，还是需要关系数据库。
  
### 非关系型数据库
　　NoSQL一词，用于指代那些非关系型的，分布式的，且一般不保证遵循 ACID 原则的数据存储系统（NoSQL遵循的是BASE原则）。非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合，是传统关系型数据库的功能阉割版本。直接使用键值对存储数据，一般不支持ACID特性多用于分布式场景中。
#### 优点
  * 并发读写性能强悍：通过减少用不到或很少用的功能（如无需经过sql层的解析），来大幅度提高读写性能，适合高并发的海量数据的高效率读写需求。
  * 扩展性好：没有固定的表结构，基于键值对结构存储，数据没有耦合性，容易水平扩展；
  * 存储数据的格式多样：nosql的存储格式是key-value形式、文档形式、图片形式等等，文档形式、图片形式等等，关系型数据库则只支持基础类型。
#### 瓶颈
  * 非关系型数据库由于很少的约束，只适合存储一些较为简单的数据，不能够提供像 SQL 所提供的 where 这种对于字段属性值情况的查询。对于需要进行较复杂查询的数据，SQL 数据库显的更为合适。

### NoSQL遵循BASE原则
  * 基本可用（Basically Availble）：在绝大多数时间内可用，支持分区失败（Sharding碎片划分数据库），出了问题服务仅降级（部分不可用）。
  * 软状态/柔性（Soft-state）：事务"Soft state" 可以理解为"无连接"的, 而 "Hard state" 是"面向连接"的。 软状态就是数据状态不要求任意时刻都保持同步，可以有一段时间不同步。
  * 最终一致性（Eventual Consistency）：最终数据是一致的就可以了。在一定的时间内数据会达到一致的状态，而不是时时一致。

### 日志结构合并树（Log-Structured Merge Tree）
  * LSM Tree是为了优化数据库写性能而出现的。在牺牲了数据库一定的读能力的条件下，极大改善了数据库的写能力。它要求一棵树始终位于内存（小树），另一棵树位于磁盘（大树），小树可以是红黑树、跳跃表（参考LevelDB），甚至可以是B树，而大树则通常是B树或其变种，所以LSM Tree中的索引是可以选择的。
  * **传统的关系数据库使用B+树最大的性能问题是会产生大量的随机IO，随着新数据的插入，叶子节点会慢慢分裂，逻辑上连续的叶子节点在物理上往往不连续，甚至分离的很远，做范围查询时，会产生大量读随机写**，因为你无法保证节点常驻内存，尤其是当B+树管理的索引量很大的时候。这导致数据库读写性能急剧下降。
  * LSM树的设计思想是把一颗大树拆分成N棵小树，它首先写入到内存中（内存没有寻道速度的问题，随机写的性能得到大幅提升），在内存中构建一颗有序小树，随着小树越来越大，内存的小树会flush到磁盘上。**磁盘中的树定期可以做merge操作，合并成一棵大树以优化读性能。无论是内存的小树flush到磁盘，还是磁盘中的树合并，都是顺序写为主，极大程度地避免了磁盘随机写，因此具有写入速度快的特点**。
  
### LSM Tree与level的关系
  * LSM存储模型：牺牲读性能，提高随机写性能；
  * Level存储架构：尽可能地优化读性能，同时减少对写性能的影响。假设没有Level的概念，每次读请求都要去访问多个文件，于是才有Level的概念去做compaction，尽可能减少读取的文件数，同时又保证了每次Compaction IO的数据量，保证对正常的写请求影响不会太大；
  * LSM和Level之间是相互均衡的关系，它们决定了读写性能。在不同的应用场景下，我们需要在两者间有所取舍。

### LSM Tree读性能如何保证
　　LSM Tree放弃磁盘读性能来换取写的顺序性，但不代表LSM Tree的读性能就不理想。
  * 内存的速度远超磁盘，1000倍以上。而读取的性能提升，主要还是依靠内存命中率而非磁盘读的次数。
  * 写入占用更少磁盘的IO，读取就能获取更长时间的磁盘IO使用权，从而也可以提升读取效率。例如LevelDb的SSTable虽然降低了了读的性能，但如果数据的读取命中率有保障的前提下，因为读取能够获得更多的磁盘IO机会，因此读取性能基本没有降低，甚至还会有提升。而写入的性能则会获得较大幅度的提升，基本上是5~10倍左右。

### LevelDB整体结构
  * MemTable：即内存中的SSTable，新数据会写入到这里，然后批量写入磁盘，以此提高写的吞吐量。
  * Log：写MemTable前会写Log文件，即用WAL(Write Ahead Log)方式记录日志，如果机器突然掉电，内存中的MemTable丢失了，还可以通过日志恢复数据。WAL日志是很多传统数据库例如MySQL采用的技术。
  * Immutable MemTable。内存中的MemTable达到指定的大小后，将不再接收新数据，同时会有新的MemTable产生，新数据写入到这个新的MemTable里，Immutable MemTable随后会写入硬盘，变成一个SST文件。
  * SSTable文件。即硬盘上的SSTable，文件尾部追加了一块索引，记录key->offset，提高随机读的效率。SST文件为Level 0到Level N多层，每一层包含多个SST文件；单个SST文件容量随层次增加成倍增长；Level0的SST文件由Immutable MemTable直接Dump产生，其他Level的SST文件由其上一层的文件和本层文件归并产生。
  * Manifest文件。 Manifest文件中记录SST文件在不同Level的分布，单个SST文件的最大最小key，以及其他一些LevelDB需要的元信息。
  * Current文件。从上面的介绍可以看出，LevelDB启动时的首要任务就是找到当前的Manifest，而Manifest可能有多个。Current文件简单的记录了当前Manifest的文件名。
  
### VersionSet, Version, VersionEdit
  * Version保存当前磁盘以及内存中的文件信息，一般只有一个version为”current version”。同时还保存了一系列的历史version，这些version的存在是因为有读操作还在引用（iterator和get，Compaction操作后会产生新的version作为current version
  * VersionSet就是一系列Version的集合
  * VersionEdit表示Version之间的变化，表示增加了多少文件，删除了多少文件
  
### Snapshot
  * 快照提供了一个当前KV存储的一个可读视图，使得读取操作不受写操作影响，可以在读操作过程中始终看到一致的数据
  * 一个快照对应当前存储的最新数据版本号

### MemTable, Immutable MemTable
  * MemTable是leveldb的内存缓存。它也提供了数据的写入，删除，读取等操作接口。它内部采用Skiplist作为数据组织结构，同时它使用自己实现的Arena作为内存分配器。
  * Immutable MemTable和MemTable结构是完全一样的，只不过它是只读的，当MemTable中的数据量达到一定程度时会转换成Immutable MemTable。
  
### 跳跃表（Skiplist）
 * 单纯比较单线程性能，跳跃表和RB-Tree可以说相差不大，都是O(logN)，但跳跃表的实现比RB-Tree简单很多。
 * 跳跃表存储的节点更多，更为消耗内存。
 * 在并发环境下，跳跃表的优势体现在更新的局部性更好，涉及的节点更少，锁需要盯住的节点更少，多线程之间争夺锁的代价也就更小。

### TableBuilder, BlockBuilder
  * TableBuilder: 将数据按照sst文件的格式组织后，写入sst文件
  * BlockBuilder: 将数据按照Block的格式组织起来，被TableBuilder使用
  * BuildTable: 在将MemTable的数据写入sst时调用，使用TableBuilder来实现

### TableCache, BlockCache
　　TableCache和BlockCache底层都是用了LRUCache的数据结构
  * TableCache: 缓存了Table相关的信息，包括Table对应的File指针，以及Table对象的指针，Table对象包含了Table的元数据，索引信息等。可以防止过多的文件open
  * BlockCache: 缓存块数据

### leveldb的Put写过程
  * `DB::Put()`操作会将(key,value)转化成writebatch后，通过`DBImpl::Write()`接口来完成
  * 在`DBImpl::Write()`之前需要通过`DBImpl::MakeRoomForWrite()`来保证MemTable有空间来接受写请求，这个过程中可能阻塞写请求，以及进行Compaction;
  * `DBImpl::BuildBatchGroup()`类似于缓冲区，尽可能的将多个writebatch合并在一起然后写下去，能够提升吞吐量;
  * `Log::Write:AddRecord()`就是在写入MemTable之前，先在操作写入到Log文件中;
  * 最后`WriteBatchInternal::InsertInto()`会将数据写入到MemTable中。

### leveldb的Get读过程
  * 首先判断options.snapshot是否为空，如果为不为空，快照值就取这个值，否则取最新数据的版本号;
  * 依次尝试去内存中的MemTable和Immutable MemTable中查找；
  * 在VersionSet中去查找：先逐层查找，确定key可能所在的文件。然后根据文件编号，在TableCache中查找，如果未命中，会将Table信息Load到cache中。再根据Table信息，确定key可能所在的Block。最后在BlockCache中查找Block，如果未命中，会将Block load到Cache中。然后在Block内查找key是否命中。
  * 更新读数据的统计信息，作为一个ssTable是否应该进行Compaction的依据。
  * 最后释放对Memtable，Immutable MemTable，VersionSet的引用

### leveldb对LSM Tree读性能的优化
  * Bloom filter：就是个带随即概率的bitmap,可以快速的得知某一个小的有序结构里有没有指定的数据。如果没有就不必进行二分查找，而只需简单的计算几次就能知道数据所在的ssTable，通过空间换取时间，效率得到了提升。
  * Compact：将小树合并为大树：在大树上使用二分查找的效率比在多颗小树下进行二分查找要快得多（m棵小树需要`(N/m)*logN`）。
 
### leveldb的Compaction合并过程
　　在leveldb中compaction主要包括Manual Compaction和Auto Compaction，在Auto Compaction中又包含了MemTable Compaction和SSTable Compaction。
#### Manual Compaction
　　leveldb中manual compaction是用户指定需要做compaction的key range，调用接口CompactRange来实现，它的主要流程为：
  * 计算和Range有重合的MaxLevel；
  * 从level 0 到 MaxLevel依次在每层对这个Range做Compaction；
  * 做Compaction时会限制选择做Compaction文件的大小，这样可能每个level的CompactRange可能需要做多次Compaction才能完成。
### SSTable Compaction
##### 启动条件（条件1的优先级高于条件2）
  * 每个Level的文件大小或文件数超过了这个Level的限制（L0对比文件个数，其它Level对比文件大小。主要是因为L0文件之间可能重叠，文件过多影响读访问，而其它level文件不重叠，限制文件总大小，可以防止一次compaction IO过重）；
  * 含有被寻道次数超过一定阈值的文件(这个是指读请求查找可能去读多个文件，如果最开始读的那个文件未查找到，那么这个文件就被认为寻道一次，当文件的寻道次数达到一定数量时，就认为这个文件应该去做compaction)。
##### 触发条件
  * 任何改变了上面两个条件的操作，都会触发Compaction，即调用MaybeScheduleCompaction；
  * 涉及到第一个条件改变，就是会改变某层文件的文件数目或大小，而只有Compaction操作之后才会改变这个条件；
  * 涉及到第二个条件的改变，可能是读操作和scan操作(scan操作是每1M数据采样一次，获得读最后一个key所寻道的文件，1M数据的cost大约为一次寻道)。
##### 文件选取
  * 每个level都会记录上一次Compaction选取的文件所含Key的最大值，作为下次compaction选取文件的起点；
  * 对于根据启动条件1所做的Compaction，选取文件就从上次的点开始选取，这样保证每层每个文件都会选取到；
  * 对于根据启动条件2所做的Compaction，需要做compaction的文件本身就已经确定了Level + 1层文件的选取，就是和level层选取的文件有重合的文件；
  * 在leveldb中在L层会选取1个文件，理论上这个文件最多覆盖的文件数为12个（leveldb中默认一个文件最大为2M，每层的最大数据量按照10倍增长。这样L层的文件在未对齐的情况下最多覆盖L+1层的12个文件），这样可以控制一次Compaction的最大IO为（1+12）* 2M读IO，总的IO不会超过52M。
### MemTable Compaction
　　MemTable Compaction最重要的是产出的文件所在层次的选择，它必须满足如下条件： 假设最终选择层次L，那么文件必须和`[0, L-1]`所有层的文件都没有重合，且对L+1层文件的覆盖不能超过一定的阈值（保证Compaction IO可控)。
##### Compaction文件产出时机
  * 文件大小达到一定的阈值；
  * 产出文件对Level+2层有交集的所有文件的大小超过一定阈值。
### Compaction时key丢弃的两个条件
  * last_sequence_for_key <= smallest_snapshot (有一个更新的同样的user_key比最小快照要小）；
  * key_type == del && key <= smallest_snapshot && IsBaseLevelForKey（key的类型是删除，且这个key的版本比最小快照要小，并且在更高Level没有同样的user_key)。
 
### 

### 
