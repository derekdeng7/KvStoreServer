# leveldb

### 关系型数据库：
　　关系型数据库，是指采用了关系模型来组织数据的数据库，最大特点就是事务的一致性。简单来说，关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织。
#### 优点
  * 容易理解：二维表结构是非常贴近逻辑世界一个概念，关系模型相对网状、层次等其他模型来说更容易理解；
  * 使用方便：通用的SQL语言使得操作关系型数据库非常方便；
  * 易于维护：丰富的完整性(实体完整性、参照完整性和用户定义的完整性)大大减低了数据冗余和数据不一致的概率；
#### 瓶颈
  * 高并发读写需求：网站的用户并发性非常高，往往达到每秒上万次读写请求，对于传统关系型数据库来说，硬盘I/O是一个很大的瓶颈
  * 海量数据的高效率读写：网站每天产生的数据量是巨大的，对于关系型数据库来说，在一张包含海量数据的表中查询，效率是非常低的
  * 高扩展性和可用性：在基于web的结构当中，数据库是最难进行横向扩展的，当一个应用系统的用户量和访问量与日俱增的时候，数据库却没有办法像web server和app server那样简单的通过添加更多的硬件和服务节点来扩展性能和负载能力。对于很多需要提供24小时不间断服务的网站来说，对数据库系统进行升级和扩展 是非常痛苦的事情，往往需要停机维护和数据迁移。
  
### 对网站来说，关系型数据库的很多特性不再需要
  * 事务一致性：关系型数据库在对事物一致性的维护中有很大的开销，而现在很多web2.0系统对事物的读写一致性都不高。
  * 读写实时性：对关系数据库来说，插入一条数据之后立刻查询，是肯定可以读出这条数据的，但是对于很多web应用来说，并不要求这么高的实时性，比如发一条消息之后，过几秒乃至十几秒之后才看到这条动态是完全可以接受的。
  * 复杂SQL，特别是多表关联查询：任何大数据量的web系统，都非常忌讳多个大表的关联查询，以及复杂的数据分析类型的复杂SQL报表查询，特别是SNS类型的网站，从需求以及产品阶级角度，就避免了这种情况的产生。往往更多的只是单表的主键查询，以及单表的简单条件分页查询，SQL的功能极大的弱化了。
  * 在关系型数据库中，导致性能欠佳的最主要原因是多表的关联查询，以及复杂的数据分析类型的复杂SQL报表查询。为了保证数据库的ACID特性，我们必须尽量按照其要求的范式进行设计，关系型数据库中的表都是存储一个格式化的数据结构。每个元组字段的组成都是一样，即使不是每个元组都需要所有的字段， 但数据库会为每个元组分配所有的字段，这样的结构可以便于标语表之间进行链接等操作，但从另一个角度来说它也是关系型数据库性能瓶颈的一个因素。
  
### 非关系型数据库出现的原因
  * 关系型数据库的最大特点就是事务的一致性：传统的关系型数据库读写操作都是事务的，具有ACID的特点，这个特性使得关系型数据库可以用于几乎所有对一致性有要求的系统中，如典型的银行系统。但是，在网页应用中，尤其是SNS应用中，一致性却不是显得那么重要，比如，两个人看到同一好友的数据更新的时间差那么几秒是可以容忍的，因此，关系型数据库的最大特点在这里已经无用武之地，起码不是那么重要了。
  * 相反地，关系型数据库为了维护一致性所付出的巨大代价就是其读写性能比较差，而像微博、facebook这类SNS的应用，对并发读写能力要求极高，关系型数据库已经无法应付（在读方面，传统上为了克服关系型数据库缺陷，提高性能，都是增加一级memcache来静态化网页，而在SNS中，变化太快，memchache已经无能为力了），因此，必须用新的一种数据结构存储来代替关系数据库。
  * 关系数据库的另一个特点就是其具有固定的表结构，因此，其扩展性极差，而在SNS中，系统的升级，功能的增加，往往意味着数据结构巨大变动，这一点关系型数据库也难以应付，需要新的结构化数据存储。
  * 于是，非关系型数据库应运而生，由于不可能用一种数据结构化存储应付所有的新的需求，因此，非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合。必须强调的是，数据的持久存储，尤其是海量数据的持久存储，还是需要关系数据库。
  
### 非关系型数据库
　　NoSQL一词，用于指代那些非关系型的，分布式的，且一般不保证遵循 ACID 原则的数据存储系统（NoSQL遵循的是BASE原则）。非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合，是传统关系型数据库的功能阉割版本。直接使用键值对存储数据，一般不支持ACID特性多用于分布式场景中。
#### 优点
  * 并发读写性能强悍：通过减少用不到或很少用的功能（如无需经过sql层的解析），来大幅度提高读写性能，适合高并发的海量数据的高效率读写需求。
  * 扩展性好：没有固定的表结构，基于键值对结构存储，数据没有耦合性，容易水平扩展；
  * 存储数据的格式多样：nosql的存储格式是key-value形式、文档形式、图片形式等等，文档形式、图片形式等等，关系型数据库则只支持基础类型。
#### 瓶颈
  * 非关系型数据库由于很少的约束，只适合存储一些较为简单的数据，不能够提供像 SQL 所提供的 where 这种对于字段属性值情况的查询。对于需要进行较复杂查询的数据，SQL 数据库显的更为合适。

### NoSQL遵循BASE原则
  * 基本可用（Basically Availble）：在绝大多数时间内可用，支持分区失败（Sharding碎片划分数据库），出了问题服务仅降级（部分不可用）。
  * 软状态/柔性（Soft-state）：事务"Soft state" 可以理解为"无连接"的, 而 "Hard state" 是"面向连接"的。 软状态就是数据状态不要求任意时刻都保持同步，可以有一段时间不同步。
  * 最终一致性（Eventual Consistency）：最终数据是一致的就可以了。在一定的时间内数据会达到一致的状态，而不是时时一致。

### 日志结构合并树（Log-Structured Merge Tree）
  * LSM Tree是为了优化数据库写性能而出现的。在牺牲了数据库一定的读能力的条件下，极大改善了数据库的写能力。它要求一棵树始终位于内存（小树），另一棵树位于磁盘（大树），小树可以是红黑树、跳跃表（参考LevelDB），甚至可以是B树，而大树则通常是B树或其变种，所以LSM Tree中的索引是可以选择的。
  * **传统的关系数据库使用B+树最大的性能问题是会产生大量的随机IO，随着新数据的插入，叶子节点会慢慢分裂，逻辑上连续的叶子节点在物理上往往不连续，甚至分离的很远，做范围查询时，会产生大量读随机IO**，因为你无法保证节点常驻内存，尤其是当B+树管理的索引量很大的时候。这导致数据库读写性能急剧下降。
  * LSM树的设计思想是把一颗大树拆分成N棵小树，它首先写入到内存中（内存没有寻道速度的问题，随机写的性能得到大幅提升），在内存中构建一颗有序小树，随着小树越来越大，内存的小树会flush到磁盘上。**磁盘中的树定期可以做merge操作，合并成一棵大树以优化读性能。无论是内存的小树flush到磁盘，还是磁盘中的树合并，都是顺序IO为主，极大程度地避免了随机io，因此具有写入速度快的特点**。

### LSM Tree读性能如何保证
　　LSM Tree放弃磁盘读性能来换取写的顺序性，但不代表LSM Tree的读性能就不理想。
  * 内存的速度远超磁盘，1000倍以上。而读取的性能提升，主要还是依靠内存命中率而非磁盘读的次数。
  * 写入占用更少磁盘的IO，读取就能获取更长时间的磁盘IO使用权，从而也可以提升读取效率。例如LevelDb的SSTable虽然降低了了读的性能，但如果数据的读取命中率有保障的前提下，因为读取能够获得更多的磁盘IO机会，因此读取性能基本没有降低，甚至还会有提升。而写入的性能则会获得较大幅度的提升，基本上是5~10倍左右。

### LevelDB整体结构
  * MemTable：即内存中的SSTable，新数据会写入到这里，然后批量写入磁盘，以此提高写的吞吐量。
  * Log：写MemTable前会写Log文件，即用WAL(Write Ahead Log)方式记录日志，如果机器突然掉电，内存中的MemTable丢失了，还可以通过日志恢复数据。WAL日志是很多传统数据库例如MySQL采用的技术。
  * Immutable MemTable。内存中的MemTable达到指定的大小后，将不再接收新数据，同时会有新的MemTable产生，新数据写入到这个新的MemTable里，Immutable MemTable随后会写入硬盘，变成一个SST文件。
  * SSTable文件。即硬盘上的SSTable，文件尾部追加了一块索引，记录key->offset，提高随机读的效率。SST文件为Level 0到Level N多层，每一层包含多个SST文件；单个SST文件容量随层次增加成倍增长；Level0的SST文件由Immutable MemTable直接Dump产生，其他Level的SST文件由其上一层的文件和本层文件归并产生。
  * Manifest文件。 Manifest文件中记录SST文件在不同Level的分布，单个SST文件的最大最小key，以及其他一些LevelDB需要的元信息。
  * Current文件。从上面的介绍可以看出，LevelDB启动时的首要任务就是找到当前的Manifest，而Manifest可能有多个。Current文件简单的记录了当前Manifest的文件名。


### leveldb的Put写过程
  * `DB::Put()`操作会将(key,value)转化成writebatch后，通过`DBImpl::Write()`接口来完成
  * 在`DBImpl::Write()`之前需要通过`DBImpl::MakeRoomForWrite()`来保证MemTable有空间来接受写请求，这个过程中可能阻塞写请求，以及进行Compaction;
  * `DBImpl::BuildBatchGroup()`类似于缓冲区，尽可能的将多个writebatch合并在一起然后写下去，能够提升吞吐量;
  * `Log::Write:AddRecord()`就是在写入MemTable之前，先在操作写入到Log文件中;
  * 最后`WriteBatchInternal::InsertInto()`会将数据写入到MemTable中。

### leveldb的Get读过程
  * 首先判断options.snapshot是否为空，如果为不为空，快照值就取这个值，否则取最新数据的版本号;
  * 依次尝试去内存中的MemTable和Immutable MemTable中查找；
  * 在VersionSet中去查找：先逐层查找，确定key可能所在的文件。然后根据文件编号，在TableCache中查找，如果未命中，会将Table信息Load到cache中。再根据Table信息，确定key可能所在的Block。最后在BlockCache中查找Block，如果未命中，会将Block load到Cache中。然后在Block内查找key是否命中。
  * 更新读数据的统计信息，作为一个ssTable是否应该进行Compaction的依据。
  * 最后释放对Memtable，Immutable MemTable，VersionSet的引用

### leveldb对LSM Tree读性能的优化
  * Bloom filter：就是个带随即概率的bitmap,可以快速的得知某一个小的有序结构里有没有指定的数据。如果没有就不必进行二分查找，而只需简单的计算几次就能知道数据所在的ssTable，通过空间换取时间，效率得到了提升。
  * Compact：将小树合并为大树：在大树上使用二分查找的效率比在多颗小树下进行二分查找要快得多（m棵小树需要`(N/m)*logN`）。
 
### leveldb的Compaction合并过程
 
### 

### 
